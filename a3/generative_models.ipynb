{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca78085",
   "metadata": {},
   "source": [
    "## MISA (2024-2025)\n",
    "- Alohan'ny mamerina dia avereno atao Run ny notebook iray manontolo. Ny fanaovana azy dia redémarrena mihitsy ny kernel aloha (jereo menubar, safidio **Kernel$\\rightarrow$Restart Kernel and Run All Cells**).\n",
    "\n",
    "- Izay misy hoe `YOUR CODE HERE` na `YOUR ANSWER HERE` ihany no fenoina. Afaka manampy cells vaovao raha ilaina. Aza adino ny mameno references eo ambany raha ilaina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b1846",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Naive Bayes Documentation](https://scikit-learn.org/1.5/modules/naive_bayes.html)\n",
    "* [Scikit-learn QDA Documentation](https://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html)\n",
    "* [Machine Learning Mastery - Gaussian Discriminant Analysis](https://machinelearningmastery.com/linear-discriminant-analysis-with-python/)\n",
    "* [Gaussian Discriminant Analysis on Wikipedia](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n",
    "* [Bernoulli Naive Bayes on Scikit-learn ](https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.BernoulliNB.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19105c4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e424e4",
   "metadata": {},
   "source": [
    "## DO NOT USE FOR LOOP ON number of samples N but ONLY ON number of classes C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a4b0d2b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5b3a9bb5f9459df46861b5d84bda38",
     "grade": false,
     "grade_id": "cell-f4572dec0c7469a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_digits\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39598113",
   "metadata": {},
   "source": [
    "# Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7b03949",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19e957d3826dd3977f54f428a8744d6",
     "grade": false,
     "grade_id": "cell-d82471ddcebf7ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "596068c6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5735812b7d43eb37d2bd53c84670597",
     "grade": false,
     "grade_id": "cell-212a715c4b2f4e77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_priors(X, y):\n",
    "    \"\"\"\n",
    "    Prior probability for each class \n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - priors : array of shape (C,)\n",
    "    \"\"\"\n",
    "    C = np.max(y) + 1  # Nombre de classes\n",
    "    priors = np.zeros(C)\n",
    "\n",
    "    # Calculer le nombre d'occurrences pour chaque classe\n",
    "    for i in range(C):\n",
    "        priors[i] = np.sum(y == i) / len(y)\n",
    "    \n",
    "    return priors\n",
    "\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2dc84667",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4595f1d0682daf1d642222e34ca7546f",
     "grade": true,
     "grade_id": "cell-25707d195d3be37b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "priors = compute_priors(X_train, y_train)\n",
    "error = rel_error(sk_model.priors_, priors)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26d5036a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80987a776d96e04af5c7a0922be6fc7b",
     "grade": false,
     "grade_id": "cell-a4f5a8d209b51a14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_means(X, y):\n",
    "    \"\"\"\n",
    "    Mean estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - means : array of shape (C, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = np.max(y) + 1  # Nombre de classes\n",
    "    means = np.zeros((C, D))\n",
    "\n",
    "    # Calculer les moyennes pour chaque classe\n",
    "    for i in range(C):\n",
    "        # On extrait toutes les lignes correspondant à la classe i et on calcule la moyenne\n",
    "        means[i] = np.mean(X[y == i], axis=0)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d39aebd0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5139bd849307229ab94c6dc869516b",
     "grade": true,
     "grade_id": "cell-1ea0c5a7199f1d21",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "means = compute_means(X_train, y_train)\n",
    "error = rel_error(sk_model.means_, means)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83f43ffa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d440cdafa2d4b166c5220793a35fcf7",
     "grade": false,
     "grade_id": "cell-f1401a628db797ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_sigmas_gda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariances : array of shape (C, D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = np.max(y) + 1  # Nombre de classes\n",
    "    covariances = np.zeros((C, D, D))\n",
    "    \n",
    "    # Calculer la différence entre X et les moyennes de chaque classe\n",
    "    for i in range(C):\n",
    "        # Extraire les indices des échantillons appartenant à la classe i\n",
    "        class_samples = X[y == i]  # Shape: (N_i, D)\n",
    "        \n",
    "        # Calculer la covariance de la classe i\n",
    "        diff = class_samples - means[i]  # Différence entre les échantillons et la moyenne de la classe\n",
    "        covariances[i] = np.dot(diff.T, diff) / (len(class_samples)- 1)  # Produit scalaire et normalisation\n",
    "\n",
    "    return covariances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc5a7f7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a27ecc6bbc72e72cfebaffd3ede565",
     "grade": true,
     "grade_id": "cell-6b136fdb522b6eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4271848449270932e-15\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigmas_gda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbcf24c0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "824613ff0ad0e3acb8e67b499598fbba",
     "grade": false,
     "grade_id": "cell-9970ad744b99041a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigma_lda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for LDA, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = np.max(y) + 1  # Nombre de classes\n",
    "    \n",
    "    # Matrice one-hot pour les classes\n",
    "    one_hot = np.eye(C)[y]  # Shape: (N, C)\n",
    "    \n",
    "    # Calcul des écarts entre les données et les moyennes de classe\n",
    "    deviations = X[:, np.newaxis, :] - means[np.newaxis, :, :]  # Shape: (N, C, D)\n",
    "    \n",
    "    # Pondérer les écarts par la classe correspondante\n",
    "    weighted_deviations = one_hot[:, :, np.newaxis] * deviations  # Shape: (N, C, D)\n",
    "    \n",
    "    # Somme pondérée des covariances intra-classes\n",
    "    covariance = np.einsum('ncd,nce->de', weighted_deviations, deviations) / N  # Shape: (D, D)\n",
    "    \n",
    "    return covariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0e4bfa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a95472e963297e49709fc0b8c212e341",
     "grade": true,
     "grade_id": "cell-686b35c7c584416e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.13626981244007e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigma_lda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f84312aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b0c0ed8697c9ae414131f3918c0037",
     "grade": false,
     "grade_id": "cell-17c0ce2515e2fc7c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_lda(X, C, priors, means, covariance):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    log_posterior = np.zeros((N, C))\n",
    "    \n",
    "    # Inverse de la matrice de covariance partagée\n",
    "    covariance_inv = np.linalg.inv(covariance)  # Shape: (D, D)\n",
    "    \n",
    "    # Calcul des poids W et des biais b\n",
    "    W = np.dot(means, covariance_inv.T)  # Shape: (C, D)\n",
    "    b = np.zeros(C)  # Initialisation des biais\n",
    "    \n",
    "    for c in range(C):\n",
    "        mean_c = means[c]\n",
    "        # b_c = -0.5 * mu_c^T * Sigma_inv * mu_c + log(prior_c)\n",
    "        b[c] = -0.5 * np.dot(mean_c, np.dot(covariance_inv, mean_c)) + np.log(priors[c])\n",
    "    \n",
    "    # Calcul des log-postérieurs\n",
    "    # log_posterior[n, c] = X[n] dot W[c] + b[c]\n",
    "    log_posterior = np.dot(X, W.T) + b  # Shape: (N, C)\n",
    "    \n",
    "    return log_posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ddec807",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb8777a126866cace4cb4d1b73225f5",
     "grade": false,
     "grade_id": "cell-7a43326dd032e8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NO TEST FOR LOG-POSTERIOR LDA. Mitambatra eo ambany ny test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e2a8ee0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2ed41a12624f40c8eabd8a1bac44cb4",
     "grade": false,
     "grade_id": "cell-cc5e3a7eddeb02ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_gda(X, C, priors, means, covariances):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation in GDA.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    log_posterior = np.zeros((N, C))\n",
    "    \n",
    "    for c in range(C):\n",
    "        # Extraire la covariance et sa décomposition\n",
    "        covariance_c = covariances[c]  # Shape: (D, D)\n",
    "        covariance_inv = np.linalg.inv(covariance_c)  # Inverse de la covariance\n",
    "        log_det_covariance = np.log(np.linalg.det(covariance_c))  # Logarithme du déterminant\n",
    "        \n",
    "        # Moyenne de la classe\n",
    "        mean_c = means[c]  # Shape: (D,)\n",
    "        \n",
    "        # Calcul de la contribution quadratique pour chaque observation\n",
    "        diff = X - mean_c  # Shape: (N, D)\n",
    "        quadratic_term = -0.5 * np.sum(diff @ covariance_inv * diff, axis=1)  # Shape: (N,)\n",
    "        \n",
    "        # Ajouter le terme constant et le log-prior\n",
    "        constant_term = -0.5 * log_det_covariance + np.log(priors[c])  # Scalaire\n",
    "        log_posterior[:, c] = quadratic_term + constant_term  # Shape: (N,)\n",
    "    \n",
    "    return log_posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c38e381",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c0afab4af1700e0a0fc48dd1118bdd",
     "grade": true,
     "grade_id": "cell-d58bf74c60153098",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5243557983786438e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "C = (np.max(y_train) + 1)\n",
    "log_posterior = compute_log_posterior_gda(X_train, C, sk_model.priors_, sk_model.means_, sk_model.covariance_)\n",
    "error = rel_error(np.asarray(sk_model._decision_function(X_train)), log_posterior)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9de0226f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea4a371e372fa034dcbf73d579c3358",
     "grade": false,
     "grade_id": "cell-f5cbad4c325e856e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbClassifier():\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        return np.argmax(log_post, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        return np.exp(log_post) / np.sum(np.exp(log_post), axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00619c96",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c234be9d70fd14a4551b6fcbf8de7ea5",
     "grade": false,
     "grade_id": "cell-1bbbe43fcaed8c4e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entraîne le classificateur LDA sur les données d'entraînement X et les étiquettes y.\n",
    "        \"\"\"\n",
    "        self.C = np.max(y) + 1  # Nombre de classes\n",
    "        self.priors = compute_priors(X, y)  # Calcul des probabilités a priori pour chaque classe\n",
    "        self.means = compute_means(X, y)    # Calcul des moyennes pour chaque classe\n",
    "        self.cov = compute_sigma_lda(X, y, self.means)  # Calcul de la matrice de covariance partagée\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        \"\"\"\n",
    "        Calcule les log-probabilités a posteriori pour chaque classe.\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N, self.C))\n",
    "\n",
    "        # Calcul des log-probabilités a posteriori pour chaque classe\n",
    "        for i in range(self.C):\n",
    "            mean_diff = X - self.means[i]  # Différence entre les données et les moyennes\n",
    "            inv_cov = np.linalg.inv(self.cov)  # Inverse de la matrice de covariance\n",
    "            log_det_cov = np.linalg.slogdet(self.cov)[1]  # Log du déterminant de la covariance\n",
    "            log_prior = np.log(self.priors[i])  # Log de la probabilité a priori de la classe\n",
    "\n",
    "            # Terme quadratique\n",
    "            quad_term = np.sum(mean_diff @ inv_cov * mean_diff, axis=1)\n",
    "\n",
    "            # Log-probabilité a posteriori\n",
    "            log_post[:, i] = -0.5 * (quad_term + log_det_cov) + log_prior\n",
    "\n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bad71564",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "470a4776ad0f7dd0fa6df62af2985724",
     "grade": true,
     "grade_id": "cell-103960c9425d1e47",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "pred = lda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca8c6e3b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c02ef4c722a12c047cdd79a33b701bf",
     "grade": false,
     "grade_id": "cell-a86acf06e6c80728",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.covariances = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Entraîne le classificateur QDA sur les données d'entraînement X et les étiquettes y.\n",
    "        \"\"\"\n",
    "        self.C = np.max(y) + 1  # Nombre de classes\n",
    "        self.priors = compute_priors(X, y)  # Calcul des probabilités a priori pour chaque classe\n",
    "        self.means = compute_means(X, y)    # Calcul des moyennes pour chaque classe\n",
    "        \n",
    "        # Calcul des matrices de covariance pour chaque classe\n",
    "        self.covariances = []\n",
    "        for i in range(self.C):\n",
    "            # Extraire les données correspondant à la classe i\n",
    "            class_data = X[y == i]\n",
    "            # Calcul de la matrice de covariance de la classe i\n",
    "            cov = np.cov(class_data, rowvar=False)\n",
    "            self.covariances.append(cov)\n",
    "        \n",
    "        self.covariances = np.array(self.covariances)  # Liste de matrices de covariance pour chaque classe\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        \"\"\"\n",
    "        Calcule les log-probabilités a posteriori pour chaque classe.\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N, self.C))\n",
    "        \n",
    "        for i in range(self.C):\n",
    "            # Moyenne et covariance de la classe i\n",
    "            mean_i = self.means[i]\n",
    "            cov_i = self.covariances[i]\n",
    "            prior_i = self.priors[i]\n",
    "            \n",
    "            # Calcul du terme quadratique\n",
    "            mean_diff = X - mean_i  # Différence entre les données et la moyenne de la classe\n",
    "            inv_cov = np.linalg.inv(cov_i)  # Inverse de la matrice de covariance\n",
    "            log_det_cov = np.linalg.slogdet(cov_i)[1]  # Log du déterminant de la covariance\n",
    "            \n",
    "            # Terme quadratique : (X - μ_i)^T Σ_i^-1 (X - μ_i)\n",
    "            quad_term = np.sum(mean_diff @ inv_cov * mean_diff, axis=1)\n",
    "            \n",
    "            # Log-probabilité a posteriori\n",
    "            log_post[:, i] = -0.5 * (quad_term + log_det_cov) + np.log(prior_i)\n",
    "        \n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eaceff8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e49782d08f05716006eaa10b9483f",
     "grade": true,
     "grade_id": "cell-407cb9988a114256",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e74ae0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7666654f5e7cfcd44a8c2dc0291c0ed9",
     "grade": true,
     "grade_id": "cell-1d95b01b2541d240",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5128081023261472e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict_proba(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict_proba(X_train)\n",
    "\n",
    "error = rel_error(pred, sk_pred)\n",
    "print(error)\n",
    "assert error < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17af43",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2639cfb",
   "metadata": {},
   "source": [
    "##  Bernouilli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87252e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X_train2, y_train2 = data.data, data.target\n",
    "X_train2_transf = Binarizer().fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04021ee0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70742cc3e580d8bfdbf0b9de07a87912",
     "grade": false,
     "grade_id": "cell-d5b51da0e0b8dcc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BernoulliNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None  # Probabilités a priori des classes\n",
    "        self.C = None  # Nombre de classes\n",
    "        self.theta = None  # Matrice des probabilités conditionnelles pour chaque caractéristique\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estime le paramètre theta pour chaque caractéristique et chaque classe.\n",
    "        Aucune boucle sur les échantillons N, mais seulement sur le nombre de classes C.\n",
    "        \"\"\"\n",
    "        N, D = X.shape  # N : nombre d'échantillons, D : nombre de caractéristiques\n",
    "        self.C = np.max(y) + 1  # Calcul du nombre de classes\n",
    "        self.priors = np.zeros(self.C)  # Initialisation des probabilités a priori\n",
    "        self.theta = np.zeros((D, self.C))  # Matrice des probabilités pour chaque caractéristique et chaque classe\n",
    "        \n",
    "        # Calcul des probabilités a priori pour chaque classe\n",
    "        for c in range(self.C):\n",
    "            self.priors[c] = np.sum(y == c) / N  # P(class = c)\n",
    "        \n",
    "        # Calcul des probabilités conditionnelles pour chaque caractéristique et chaque classe\n",
    "        for c in range(self.C):\n",
    "            X_class = X[y == c]  # Sélectionner les échantillons de la classe c\n",
    "            # Ajout d'un facteur de régularisation pour éviter les probabilités de 0\n",
    "            self.theta[:, c] = (np.sum(X_class, axis=0) + 1) / (X_class.shape[0] + 2)  # +1 dans le numérateur et +2 dans le dénominateur\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        \"\"\"\n",
    "        Calcule les log-posteriori pour chaque classe et chaque échantillon.\n",
    "        \"\"\"\n",
    "        N, D = X.shape  # N : nombre d'échantillons, D : nombre de caractéristiques\n",
    "        log_post = np.zeros((N, self.C))  # Matrice des log-postériori\n",
    "        \n",
    "        # Calcul des log-posteriori pour chaque classe\n",
    "        for c in range(self.C):\n",
    "            # Ajout d'un facteur de régularisation pour éviter les log(0)\n",
    "            log_post[:, c] = np.log(self.priors[c]) + np.dot(X, np.log(self.theta[:, c])) + np.dot(1 - X, np.log(1 - self.theta[:, c]))\n",
    "        \n",
    "        return log_post\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a70e61a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa098602d1a9e4c9cdca9cf73180a44",
     "grade": true,
     "grade_id": "cell-f960b1ec2ce34b3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.8636616583194212\n",
      "Your Accuracy :  0.8636616583194212\n"
     ]
    }
   ],
   "source": [
    "sk_model = BernoulliNB()\n",
    "sk_model.fit(X_train2_transf, y_train2)\n",
    "sk_pred = sk_model.predict(X_train2_transf)\n",
    "\n",
    "model = BernoulliNaiveBayes()\n",
    "model.fit(X_train2_transf, y_train2)\n",
    "pred = model.predict(X_train2_transf)\n",
    "\n",
    "sk_acc = accuracy_score(y_train2, sk_pred)\n",
    "model_acc = accuracy_score(y_train2, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d8dc6",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99588c0d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d67f1b1383503b5e5203c265f59b99d",
     "grade": false,
     "grade_id": "cell-186f17a680895047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None  # Probabilités a priori des classes\n",
    "        self.C = None  # Nombre de classes\n",
    "        self.mu = None  # Moyennes pour chaque classe\n",
    "        self.sigma = None  # Variances pour chaque classe\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estime les paramètres mu et sigma pour chaque classe.\n",
    "        Aucune boucle sur les échantillons N, mais seulement sur le nombre de classes C.\n",
    "        \"\"\"\n",
    "        N, D = X.shape  # N : nombre d'échantillons, D : nombre de caractéristiques\n",
    "        self.C = np.max(y) + 1  # Nombre de classes\n",
    "        self.priors = compute_priors(X, y)  # Calcul des priors\n",
    "        self.mu = compute_means(X, y)  # Calcul des moyennes\n",
    "        self.sigma = np.zeros((D, self.C))  # Initialisation des variances\n",
    "        \n",
    "        # Calcul des variances pour chaque classe\n",
    "        for c in range(self.C):\n",
    "            X_class = X[y == c]  # Échantillons de la classe c\n",
    "            self.sigma[:, c] = np.var(X_class, axis=0)  # Variance pour chaque caractéristique\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        \"\"\"\n",
    "        Calcule les log-posteriori pour chaque classe et chaque échantillon.\n",
    "        \"\"\"\n",
    "        N, D = X.shape  # N : nombre d'échantillons, D : nombre de caractéristiques\n",
    "        log_post = np.zeros((N, self.C))  # Matrice des log-postériori\n",
    "        \n",
    "        # Calcul des log-posteriori pour chaque classe\n",
    "        for c in range(self.C):\n",
    "            # Calcul du terme log-likelihood\n",
    "            log_likelihood = -0.5 * np.sum(np.log(2 * np.pi * self.sigma[:, c])) - 0.5 * np.sum(((X - self.mu[:, c]) ** 2) / self.sigma[:, c], axis=1)\n",
    "            log_post[:, c] = np.log(self.priors[c]) + log_likelihood\n",
    "        \n",
    "        return log_post\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2072fea0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d510e4b6069f1d0549606f4a4a12416",
     "grade": true,
     "grade_id": "cell-7ac37952b1e80482",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.96\n",
      "Your Accuracy :  0.96\n"
     ]
    }
   ],
   "source": [
    "sk_model = GaussianNB()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "model = GaussianNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "sk_acc = accuracy_score(y_train, sk_pred)\n",
    "model_acc = accuracy_score(y_train, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
